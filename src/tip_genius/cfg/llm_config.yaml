# LLM Configuration File
#
# IMPORTANT: After adding a new LLM configuration here, you must also:
# 1. Enable it in tip_genius_config.yaml under 'llm_provider_options'
# 2. Add the API key to GitHub workflow (.github/workflows/match-predictions.yaml)
#    Example: PROVIDER_API_KEY: ${{ secrets.PROVIDER_API_KEY }}
# 3. Add the API key to GitHub Secrets in the repository settings

mistral-medium:
  api_rate_limit: 8 # requests per minute for free tier
  api_key_env_name: MISTRAL_API_KEY
  base_url: https://api.mistral.ai/v1
  operation: chat/completions
  model: mistral-medium-latest
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192
    response_format:
      type: 'json_object'

deepseek-chat:
  api_key_env_name: DEEPSEEK_API_KEY
  base_url: https://api.deepseek.com
  operation: chat/completions
  model: deepseek-chat
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192
    response_format:
      type: 'json_object'

google-gemini-flash:
  api_rate_limit: 8 # requests per minute for free tier
  api_key_env_name: GOOGLE_API_KEY
  base_url: https://generativelanguage.googleapis.com/v1beta
  operation: generateContent # alternative: streamGenerateContent for stream
  model: gemini-2.5-flash-preview-05-20
  kwargs:
    temperature: 0.0
    maxOutputTokens: 8192
    response_mime_type: 'application/json'

microsoft-phi-medium:
  api_key_env_name: DEEPINFRA_API_KEY
  base_url: https://api.deepinfra.com/v1
  operation: openai/chat/completions
  model: microsoft/phi-4
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192
    response_format:
      type: 'json_object'

meta-llama-400b:
  api_key_env_name: DEEPINFRA_API_KEY
  base_url: https://api.deepinfra.com/v1
  operation: openai/chat/completions
  model: meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192
    response_format:
      type: 'json_object'

openai-gpt-mini:
  api_key_env_name: OPENAI_API_KEY
  base_url: https://api.openai.com/v1
  operation: chat/completions
  model: gpt-5-mini
  kwargs:
    stream: false
    max_completion_tokens: 8192
    response_format:
      type: 'json_object'

anthropic-claude-haiku:
  api_key_env_name: ANTHROPIC_API_KEY
  base_url: https://api.anthropic.com/v1
  operation: messages
  model: claude-3-5-haiku-20241022
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192

openrouter-grok:
  api_key_env_name: OPENROUTER_API_KEY
  base_url: https://openrouter.ai/api/v1
  operation: chat/completions
  model: x-ai/grok-3-mini
  kwargs:
    temperature: 0.0
    stream: false
    max_tokens: 8192
    response_format:
      type: 'json_object'
  optional_headers:
    HTTP-Referer: 'https://tip-genius.vercel.app'
    X-Title: 'Tip Genius'
